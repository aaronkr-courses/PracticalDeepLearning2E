#
#  file: vgg8_runs
#
#  Use the VGG8 model to train 5x models for dropout 0, 1, and 2
#  and batch norm
#
#  RTK, 15-Aug-2023
#  Last update:  16-Aug-2023
#
################################################################
mkdir runs 2>/dev/null

#  with batch normalization (no dropout)
python3 -W ignore vgg8.py 128 10 0 0.25 1 runs/vgg_b128_e10_batchnorm_run0
python3 -W ignore vgg8.py 128 10 0 0.25 1 runs/vgg_b128_e10_batchnorm_run1
python3 -W ignore vgg8.py 128 10 0 0.25 1 runs/vgg_b128_e10_batchnorm_run2
python3 -W ignore vgg8.py 128 10 0 0.25 1 runs/vgg_b128_e10_batchnorm_run3
python3 -W ignore vgg8.py 128 10 0 0.25 1 runs/vgg_b128_e10_batchnorm_run4

#  no dropout or batch norm on conv layers
python3 -W ignore vgg8.py 128 10 0 0.25 0 runs/vgg_b128_e10_dropout0_run0
python3 -W ignore vgg8.py 128 10 0 0.25 0 runs/vgg_b128_e10_dropout0_run1
python3 -W ignore vgg8.py 128 10 0 0.25 0 runs/vgg_b128_e10_dropout0_run2
python3 -W ignore vgg8.py 128 10 0 0.25 0 runs/vgg_b128_e10_dropout0_run3
python3 -W ignore vgg8.py 128 10 0 0.25 0 runs/vgg_b128_e10_dropout0_run4

#  classic dropout on conv layers, no batch norm
python3 -W ignore vgg8.py 128 10 1 0.25 0 runs/vgg_b128_e10_dropout1_run0
python3 -W ignore vgg8.py 128 10 1 0.25 0 runs/vgg_b128_e10_dropout1_run1
python3 -W ignore vgg8.py 128 10 1 0.25 0 runs/vgg_b128_e10_dropout1_run2
python3 -W ignore vgg8.py 128 10 1 0.25 0 runs/vgg_b128_e10_dropout1_run3
python3 -W ignore vgg8.py 128 10 1 0.25 0 runs/vgg_b128_e10_dropout1_run4

#  spatial dropout on conv layers, no batch norm
python3 -W ignore vgg8.py 128 10 2 0.25 0 runs/vgg_b128_e10_dropout2_run0
python3 -W ignore vgg8.py 128 10 2 0.25 0 runs/vgg_b128_e10_dropout2_run1
python3 -W ignore vgg8.py 128 10 2 0.25 0 runs/vgg_b128_e10_dropout2_run2
python3 -W ignore vgg8.py 128 10 2 0.25 0 runs/vgg_b128_e10_dropout2_run3
python3 -W ignore vgg8.py 128 10 2 0.25 0 runs/vgg_b128_e10_dropout2_run4

