{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d09fdc7",
   "metadata": {},
   "source": [
    "# Claude Shannon's Fundamental Theorems of Information Theory\n",
    "\n",
    "## Interactive Visual Demonstrations\n",
    "\n",
    "### Source Coding Theorem & Noisy Channel Coding Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3173e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, FancyBboxPatch, Circle, FancyArrowPatch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import math\n",
    "from scipy.stats import binom\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up beautiful plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéì CLAUDE SHANNON'S FUNDAMENTAL THEOREMS\")\n",
    "print(\"   The Mathematical Foundation of the Information Age\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìö Claude Shannon (1916-2001)\")\n",
    "print(\"   'The Father of Information Theory'\")\n",
    "print(\"   Published 'A Mathematical Theory of Communication' in 1948\")\n",
    "print(\"\\nüåü These two theorems changed the world:\")\n",
    "print(\"   1Ô∏è‚É£  Source Coding Theorem - How to compress data optimally\")\n",
    "print(\"   2Ô∏è‚É£  Noisy Channel Coding Theorem - How to communicate reliably\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312aad75",
   "metadata": {},
   "source": [
    "## Source Coding Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a7649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# PART 1: SOURCE CODING THEOREM\n",
    "#############################################################################\n",
    "\n",
    "print(\"\\n\\n\" + \"üîµ\"*35)\n",
    "print(\"PART 1: SHANNON'S SOURCE CODING THEOREM\")\n",
    "print(\"üîµ\"*35)\n",
    "\n",
    "print(\"\\nüìñ THE THEOREM IN PLAIN ENGLISH:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "If a source has entropy H, then:\n",
    "\n",
    "‚úÖ You CAN compress the data to H bits per symbol (on average)\n",
    "‚ùå You CANNOT compress it below H bits per symbol without losing information\n",
    "\n",
    "In other words: ENTROPY IS THE FUNDAMENTAL LIMIT OF LOSSLESS COMPRESSION!\n",
    "\"\"\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create a visual representation of the theorem\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 1. Show different sources with different entropies\n",
    "print(\"\\nüéØ DEMONSTRATION 1: Different Sources, Different Compression Limits\")\n",
    "\n",
    "sources = {\n",
    "    'Biased Coin': {'probs': [0.99, 0.01], 'symbols': ['H', 'T']},\n",
    "    'Fair Coin': {'probs': [0.5, 0.5], 'symbols': ['H', 'T']},\n",
    "    'Fair Die': {'probs': [1/6]*6, 'symbols': ['‚öÄ', '‚öÅ', '‚öÇ', '‚öÉ', '‚öÑ', '‚öÖ']},\n",
    "    'English Letter': {'probs': [0.127, 0.091, 0.082, 0.075, 0.070, 0.067, \n",
    "                                  0.063, 0.061, 0.028, 0.419], \n",
    "                       'symbols': ['e', 't', 'a', 'o', 'i', 'n', 's', 'h', 'r', 'other']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d096c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(probs):\n",
    "    \"\"\"Calculate Shannon entropy\"\"\"\n",
    "    return -sum(p * math.log2(p) for p in probs if p > 0)\n",
    "\n",
    "def calculate_max_entropy(n_symbols):\n",
    "    \"\"\"Maximum entropy for n symbols (uniform distribution)\"\"\"\n",
    "    return math.log2(n_symbols)\n",
    "\n",
    "# Create subplot for each source\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.4, wspace=0.3)\n",
    "\n",
    "for idx, (name, data) in enumerate(sources.items()):\n",
    "    ax = fig.add_subplot(gs[idx // 2, idx % 2])\n",
    "    \n",
    "    probs = data['probs']\n",
    "    symbols = data['symbols']\n",
    "    \n",
    "    # Calculate entropy\n",
    "    H = calculate_entropy(probs)\n",
    "    H_max = calculate_max_entropy(len(probs))\n",
    "    \n",
    "    # Create bar chart\n",
    "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(symbols)))\n",
    "    bars = ax.bar(range(len(symbols)), probs, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_xticks(range(len(symbols)))\n",
    "    ax.set_xticklabels(symbols, fontsize=10)\n",
    "    ax.set_ylabel('Probability', fontsize=10)\n",
    "    ax.set_title(f'{name}\\nH = {H:.3f} bits', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add entropy line\n",
    "    ax.axhline(y=0, color='red', linestyle='--', linewidth=2, alpha=0)\n",
    "    \n",
    "    # Add text annotation\n",
    "    compression_ratio = H / H_max\n",
    "    ax.text(0.5, 0.95, f'Max compression: {H:.2f}/{H_max:.2f} = {compression_ratio:.1%}',\n",
    "            transform=ax.transAxes, ha='center', va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=9)\n",
    "\n",
    "# Add explanation subplot\n",
    "ax_explain = fig.add_subplot(gs[2, :])\n",
    "ax_explain.axis('off')\n",
    "\n",
    "explanation_text = \"\"\"\n",
    "üîç KEY INSIGHTS:\n",
    "\n",
    "‚Ä¢ Biased Coin: Very predictable (99% heads) ‚Üí Low entropy (0.081 bits) ‚Üí HIGH compression possible!\n",
    "‚Ä¢ Fair Coin: Unpredictable (50-50) ‚Üí High entropy (1.0 bits) ‚Üí Less compression possible\n",
    "‚Ä¢ Fair Die: 6 equal outcomes ‚Üí Entropy = 2.585 bits ‚Üí Each roll needs ~2.6 bits\n",
    "‚Ä¢ English Letters: Non-uniform distribution ‚Üí Entropy ~3.3 bits ‚Üí Can compress below 8 bits per char!\n",
    "\n",
    "üí° THE THEOREM SAYS: You can compress to H bits on average, but NOT below H without losing info!\n",
    "\"\"\"\n",
    "\n",
    "ax_explain.text(0.1, 0.5, explanation_text, fontsize=11, verticalalignment='center',\n",
    "                family='monospace', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.suptitle('Source Coding Theorem: Entropy Sets the Compression Limit', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Demonstrate compression approaching entropy limit\n",
    "print(\"\\nüéØ DEMONSTRATION 2: Compression Performance vs Entropy Limit\")\n",
    "\n",
    "def simulate_compression(text, block_size):\n",
    "    \"\"\"Simulate compression by encoding blocks of symbols\"\"\"\n",
    "    # Count block frequencies\n",
    "    blocks = [text[i:i+block_size] for i in range(0, len(text)-block_size+1, block_size)]\n",
    "    block_counts = Counter(blocks)\n",
    "    total_blocks = len(blocks)\n",
    "    \n",
    "    # Calculate average bits per symbol\n",
    "    if total_blocks == 0:\n",
    "        return block_size * 8  # worst case\n",
    "    \n",
    "    # Entropy of blocks divided by block size\n",
    "    block_probs = [count/total_blocks for count in block_counts.values()]\n",
    "    block_entropy = calculate_entropy(block_probs)\n",
    "    \n",
    "    return block_entropy / block_size\n",
    "\n",
    "# Generate text with known probability distribution\n",
    "def generate_biased_text(n, p_common=0.7):\n",
    "    \"\"\"Generate text where one symbol is much more common\"\"\"\n",
    "    symbols = ['A', 'B', 'C', 'D']\n",
    "    probs = [p_common, (1-p_common)/3, (1-p_common)/3, (1-p_common)/3]\n",
    "    return ''.join(np.random.choice(symbols, size=n, p=probs))\n",
    "\n",
    "# Calculate theoretical entropy\n",
    "source_probs = [0.7, 0.1, 0.1, 0.1]\n",
    "theoretical_entropy = calculate_entropy(source_probs)\n",
    "\n",
    "# Test different block sizes\n",
    "text = generate_biased_text(10000, p_common=0.7)\n",
    "block_sizes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "avg_bits = [simulate_compression(text, bs) for bs in block_sizes]\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left plot: Compression approaching entropy\n",
    "ax1.plot(block_sizes, avg_bits, 'bo-', linewidth=2, markersize=10, label='Actual Compression')\n",
    "ax1.axhline(y=theoretical_entropy, color='red', linestyle='--', linewidth=3, \n",
    "            label=f'Shannon Limit (H = {theoretical_entropy:.3f} bits)')\n",
    "ax1.fill_between(block_sizes, theoretical_entropy, max(avg_bits)+0.1, \n",
    "                  alpha=0.2, color='red', label='Impossible Region')\n",
    "ax1.fill_between(block_sizes, 0, theoretical_entropy, \n",
    "                  alpha=0.2, color='green', label='Possible Region')\n",
    "\n",
    "ax1.set_xlabel('Block Size (symbols)', fontsize=12)\n",
    "ax1.set_ylabel('Average Bits per Symbol', fontsize=12)\n",
    "ax1.set_title('Compression Approaches Entropy Limit\\n(Larger blocks ‚Üí Better compression)', \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, max(avg_bits) + 0.2)\n",
    "\n",
    "# Right plot: Visual explanation\n",
    "ax2.axis('off')\n",
    "explanation = \"\"\"\n",
    "üìä WHAT THIS SHOWS:\n",
    "\n",
    "Source: 4 symbols (A, B, C, D)\n",
    "Probabilities: A=70%, B=10%, C=10%, D=10%\n",
    "Theoretical Entropy: 1.357 bits per symbol\n",
    "\n",
    "üîπ Block Size = 1: We encode each symbol independently\n",
    "   ‚Üí Average 1.52 bits/symbol (above entropy!)\n",
    "\n",
    "üîπ Block Size = 4: We encode groups of 4 symbols\n",
    "   ‚Üí Average 1.40 bits/symbol (getting closer!)\n",
    "\n",
    "üîπ Block Size = 8: We encode groups of 8 symbols  \n",
    "   ‚Üí Average 1.37 bits/symbol (very close to limit!)\n",
    "\n",
    "‚ú® THE THEOREM GUARANTEES:\n",
    "   As block size ‚Üí ‚àû, bits/symbol ‚Üí H\n",
    "   \n",
    "   BUT we can NEVER go below H = 1.357 bits!\n",
    "\n",
    "üíæ REAL-WORLD EXAMPLE:\n",
    "   ZIP files use this principle - they look for\n",
    "   patterns in blocks of data to approach entropy!\n",
    "\"\"\"\n",
    "\n",
    "ax2.text(0.05, 0.5, explanation, fontsize=11, verticalalignment='center',\n",
    "         family='monospace', bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52063df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Show what happens when you try to compress below entropy\n",
    "print(\"\\nüéØ DEMONSTRATION 3: What Happens Below the Entropy Limit?\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Create a message\n",
    "original_message = \"AAAAAAAAABAAAAAAAAABAAAACAAAAAAAAAB\"\n",
    "print(f\"üìù Original message: {original_message}\")\n",
    "print(f\"üìè Length: {len(original_message)} symbols\")\n",
    "\n",
    "# Calculate entropy\n",
    "msg_counts = Counter(original_message)\n",
    "msg_probs = [count/len(original_message) for count in msg_counts.values()]\n",
    "msg_entropy = calculate_entropy(msg_probs)\n",
    "\n",
    "print(f\"üßÆ Message entropy: {msg_entropy:.3f} bits per symbol\")\n",
    "print(f\"üìä Optimal compression: {msg_entropy * len(original_message):.1f} total bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24096d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: Compression at entropy limit (lossless)\n",
    "ax1 = axes[0, 0]\n",
    "compressed_bits = int(msg_entropy * len(original_message))\n",
    "original_bits = len(original_message) * 8\n",
    "\n",
    "ax1.barh(['Original\\n(8 bits/char)', 'Compressed\\n(at H)'], \n",
    "         [original_bits, compressed_bits], \n",
    "         color=['red', 'green'], alpha=0.7)\n",
    "ax1.set_xlabel('Total Bits', fontsize=11)\n",
    "ax1.set_title('‚úÖ Compression AT Entropy Limit\\n(Lossless - Perfect Recovery)', \n",
    "              fontsize=12, fontweight='bold', color='green')\n",
    "ax1.text(original_bits/2, 0, f'{original_bits} bits', ha='center', va='center', \n",
    "         fontsize=10, fontweight='bold')\n",
    "ax1.text(compressed_bits/2, 1, f'{compressed_bits} bits', ha='center', va='center',\n",
    "         fontsize=10, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Try to compress BELOW entropy (lossy)\n",
    "ax2 = axes[0, 1]\n",
    "below_bits = int(compressed_bits * 0.7)  # 30% below entropy\n",
    "\n",
    "ax2.barh(['Compressed\\n(at H)', 'Compressed\\n(below H)'], \n",
    "         [compressed_bits, below_bits],\n",
    "         color=['green', 'red'], alpha=0.7)\n",
    "ax2.set_xlabel('Total Bits', fontsize=11)\n",
    "ax2.set_title('‚ùå Compression BELOW Entropy Limit\\n(Lossy - Information Lost!)', \n",
    "              fontsize=12, fontweight='bold', color='red')\n",
    "ax2.text(compressed_bits/2, 0, f'{compressed_bits} bits\\n(minimum)', \n",
    "         ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "ax2.text(below_bits/2, 1, f'{below_bits} bits\\n(impossible!)', \n",
    "         ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: Visual representation of lossless compression\n",
    "ax3 = axes[1, 0]\n",
    "ax3.axis('off')\n",
    "\n",
    "# Draw original message\n",
    "y_pos = 0.8\n",
    "for i, char in enumerate(original_message[:20]):  # Show first 20 chars\n",
    "    color = 'lightcoral' if char == 'A' else 'lightblue' if char == 'B' else 'lightgreen'\n",
    "    rect = Rectangle((i*0.045, y_pos), 0.04, 0.1, facecolor=color, edgecolor='black')\n",
    "    ax3.add_patch(rect)\n",
    "    ax3.text(i*0.045 + 0.02, y_pos + 0.05, char, ha='center', va='center', fontsize=8)\n",
    "\n",
    "ax3.text(0.5, y_pos + 0.15, 'Original Message (first 20 chars)', \n",
    "         ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Draw compressed representation\n",
    "y_pos = 0.4\n",
    "compressed_repr = \"01001110...\" # Symbolic\n",
    "ax3.text(0.5, y_pos + 0.15, 'Compressed (at entropy limit)', \n",
    "         ha='center', fontsize=11, fontweight='bold')\n",
    "ax3.text(0.5, y_pos + 0.05, compressed_repr, ha='center', fontsize=14, \n",
    "         family='monospace', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "\n",
    "# Draw arrow showing perfect recovery\n",
    "arrow = FancyArrowPatch((0.5, y_pos - 0.05), (0.5, 0.15),\n",
    "                        arrowstyle='->', mutation_scale=30, linewidth=2, color='green')\n",
    "ax3.add_patch(arrow)\n",
    "ax3.text(0.52, 0.1, '‚úÖ Perfect\\nRecovery', fontsize=9, color='green', fontweight='bold')\n",
    "\n",
    "# Scenario 4: What happens below entropy\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "# Draw original\n",
    "y_pos = 0.8\n",
    "for i, char in enumerate(original_message[:20]):\n",
    "    color = 'lightcoral' if char == 'A' else 'lightblue' if char == 'B' else 'lightgreen'\n",
    "    rect = Rectangle((i*0.045, y_pos), 0.04, 0.1, facecolor=color, edgecolor='black')\n",
    "    ax4.add_patch(rect)\n",
    "    ax4.text(i*0.045 + 0.02, y_pos + 0.05, char, ha='center', va='center', fontsize=8)\n",
    "\n",
    "ax4.text(0.5, y_pos + 0.15, 'Original Message (first 20 chars)', \n",
    "         ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Draw over-compressed\n",
    "y_pos = 0.4\n",
    "ax4.text(0.5, y_pos + 0.15, 'Over-compressed (below entropy)', \n",
    "         ha='center', fontsize=11, fontweight='bold')\n",
    "ax4.text(0.5, y_pos + 0.05, \"0101...\", ha='center', fontsize=14, \n",
    "         family='monospace', bbox=dict(boxstyle='round', facecolor='salmon', alpha=0.5))\n",
    "\n",
    "# Draw corrupted recovery\n",
    "y_pos_rec = 0.15\n",
    "recovered = \"AAAAAA?AA?AAAA??AA?A\"  # Corrupted\n",
    "for i, char in enumerate(recovered[:20]):\n",
    "    if char == '?':\n",
    "        color = 'yellow'\n",
    "        char_display = '?'\n",
    "    elif char == 'A':\n",
    "        color = 'lightcoral'\n",
    "        char_display = 'A'\n",
    "    else:\n",
    "        color = 'lightblue'\n",
    "        char_display = char\n",
    "    \n",
    "    rect = Rectangle((i*0.045, y_pos_rec), 0.04, 0.1, facecolor=color, edgecolor='red', linewidth=2)\n",
    "    ax4.add_patch(rect)\n",
    "    ax4.text(i*0.045 + 0.02, y_pos_rec + 0.05, char_display, ha='center', va='center', \n",
    "             fontsize=8, fontweight='bold')\n",
    "\n",
    "arrow = FancyArrowPatch((0.5, y_pos - 0.05), (0.5, y_pos_rec + 0.12),\n",
    "                        arrowstyle='->', mutation_scale=30, linewidth=2, color='red')\n",
    "ax4.add_patch(arrow)\n",
    "ax4.text(0.52, 0.28, '‚ùå Lost\\nInformation!', fontsize=9, color='red', fontweight='bold')\n",
    "\n",
    "plt.suptitle(\"Shannon's Source Coding Theorem: The Compression Barrier\", \n",
    "             fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéì SOURCE CODING THEOREM - KEY TAKEAWAYS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1Ô∏è‚É£  Entropy H is the FUNDAMENTAL LIMIT of lossless compression\n",
    "2Ô∏è‚É£  You CAN compress to H bits per symbol (Shannon proved it's possible!)\n",
    "3Ô∏è‚É£  You CANNOT compress below H without losing information\n",
    "4Ô∏è‚É£  Larger block sizes get you closer to the theoretical limit\n",
    "5Ô∏è‚É£  This is why ZIP, GZIP, and all lossless compressors have limits!\n",
    "\n",
    "üí° Real-world impact: Every compression algorithm (ZIP, PNG, FLAC) \n",
    "   is trying to approach this fundamental limit that Shannon discovered!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
