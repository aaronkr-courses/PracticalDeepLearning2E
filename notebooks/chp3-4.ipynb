{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817d8c5e",
   "metadata": {},
   "source": [
    "# Chp 3 Introduction to ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorial\n",
    "def fact(n):\n",
    "    if (n <= 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return n*fact(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2602f069",
   "metadata": {},
   "source": [
    "# Chp 4 Experiments with Classical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6703acb",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c923a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris Experiments\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"    predictions  :\", clf.predict(x_test))\n",
    "    print(\"    actual labels:\", y_test)\n",
    "    print(\"    score = %0.4f\" % clf.score(x_test, y_test))\n",
    "    print()\n",
    "\n",
    "def main():\n",
    "    x = np.load(\"../data/iris/iris_features.npy\")\n",
    "    y = np.load(\"../data/iris/iris_labels.npy\")\n",
    "    N = 120 \n",
    "    x_train = x[:N]; x_test = x[N:]\n",
    "    y_train = y[:N]; y_test = y[N:]\n",
    "    xa_train=np.load(\"../data/iris/iris_train_features_augmented.npy\")\n",
    "    ya_train=np.load(\"../data/iris/iris_train_labels_augmented.npy\")\n",
    "    xa_test =np.load(\"../data/iris/iris_test_features_augmented.npy\")\n",
    "    ya_test =np.load(\"../data/iris/iris_test_labels_augmented.npy\")\n",
    "\n",
    "    print(\"Nearest centroid:\")\n",
    "    run(x_train, y_train, x_test, y_test, NearestCentroid())\n",
    "    print(\"k-NN classifier (k=3):\")\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n",
    "    print(\"Naive Bayes classifier (Gaussian):\")\n",
    "    run(x_train, y_train, x_test, y_test, GaussianNB())\n",
    "    print(\"Naive Bayes classifier (Multinomial):\")\n",
    "    run(x_train, y_train, x_test, y_test, MultinomialNB())\n",
    "    print(\"Decision tree classifier:\")\n",
    "    run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n",
    "    print(\"Random forest classifier (estimators=5):\")\n",
    "    run(xa_train, ya_train, xa_test, ya_test, RandomForestClassifier(n_estimators=5))\n",
    "\n",
    "    print(\"SVM (linear, C=1.0):\")\n",
    "    run(xa_train, ya_train, xa_test, ya_test, SVC(kernel=\"linear\", C=1.0))\n",
    "    print(\"SVM (RBF, C=1.0, gamma=0.25):\")\n",
    "    run(xa_train, ya_train, xa_test, ya_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.25))\n",
    "    print(\"SVM (RBF, C=1.0, gamma=0.001, augmented)\")\n",
    "    run(xa_train, ya_train, xa_test, ya_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.001))\n",
    "    print(\"SVM (RBF, C=1.0, gamma=0.001, original)\")\n",
    "    run(x_train, y_train, x_test, y_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.001))\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def centroids(x,y):\n",
    "    c0 = x[np.where(y==0)].mean(axis=0)\n",
    "    c1 = x[np.where(y==1)].mean(axis=0)\n",
    "    c2 = x[np.where(y==2)].mean(axis=0)\n",
    "    return [c0,c1,c2]\n",
    "\n",
    "def predict(c0,c1,c2,x):\n",
    "    p = np.zeros(x.shape[0], dtype=\"uint8\")\n",
    "    for i in range(x.shape[0]):\n",
    "        d = [((c0-x[i])**2).sum(),\n",
    "             ((c1-x[i])**2).sum(),\n",
    "             ((c2-x[i])**2).sum()]\n",
    "        p[i] = np.argmin(d)\n",
    "    return p\n",
    "\n",
    "def main():\n",
    "    x = np.load(\"../data/iris/iris_features.npy\")\n",
    "    y = np.load(\"../data/iris/iris_labels.npy\")\n",
    "    N = 120\n",
    "    x_train = x[:N]; x_test = x[N:]\n",
    "    y_train = y[:N]; y_test = y[N:]\n",
    "    c0, c1, c2 = centroids(x_train, y_train)\n",
    "    p = predict(c0,c1,c2, x_test)\n",
    "    nc = len(np.where(p == y_test)[0])\n",
    "    nw = len(np.where(p != y_test)[0])\n",
    "    acc = float(nc) / (float(nc)+float(nw))\n",
    "    print(\"predicted:\", p)\n",
    "    print(\"actual   :\", y_test)\n",
    "    print(\"test accuracy = %0.4f\" % acc)\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059011e",
   "metadata": {},
   "source": [
    "## Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC experiements\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"    score = %0.4f\" % clf.score(x_test, y_test))\n",
    "    print()\n",
    "\n",
    "def main():\n",
    "    x = np.load(\"../data/breast/bc_features_standard.npy\")\n",
    "    y = np.load(\"../data/breast/bc_labels.npy\")\n",
    "    N = 455 \n",
    "    x_train = x[:N];  x_test = x[N:]\n",
    "    y_train = y[:N];  y_test = y[N:]\n",
    "\n",
    "    print(\"Nearest centroid:\")\n",
    "    run(x_train, y_train, x_test, y_test, NearestCentroid())\n",
    "    print(\"k-NN classifier (k=3):\")\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n",
    "    print(\"k-NN classifier (k=7):\")\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))\n",
    "    print(\"Naive Bayes classifier (Gaussian):\")\n",
    "    run(x_train, y_train, x_test, y_test, GaussianNB())\n",
    "    print(\"Decision tree classifier:\")\n",
    "    run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n",
    "    print(\"Random forest classifier (estimators=5):\")\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=5))\n",
    "    print(\"Random forest classifier (estimators=50):\")\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=50))\n",
    "    print(\"SVM (linear, C=1.0):\")\n",
    "    run(x_train, y_train, x_test, y_test, SVC(kernel=\"linear\", C=1.0))\n",
    "    print(\"SVM (RBF, C=1.0, gamma=0.03333):\")\n",
    "    run(x_train, y_train, x_test, y_test, SVC(kernel=\"rbf\", C=1.0, gamma=0.03333))\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e312fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC K-Fold\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf.score(x_test, y_test)\n",
    "\n",
    "def split(x,y,k,m):\n",
    "    ns = int(y.shape[0]/m)\n",
    "    s = []\n",
    "    for i in range(m):\n",
    "    \ts.append([x[(ns*i):(ns*i+ns)],\n",
    "                  y[(ns*i):(ns*i+ns)]])\n",
    "    x_test, y_test = s[k]\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(m):\n",
    "        if (i==k):\n",
    "            continue\n",
    "        else:\n",
    "            a,b = s[i]\n",
    "            x_train.append(a)\n",
    "            y_train.append(b)\n",
    "    x_train = np.array(x_train).reshape(((m-1)*ns,30))\n",
    "    y_train = np.array(y_train).reshape((m-1)*ns)\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "def pp(z,k,s):\n",
    "    m = z.shape[1]\n",
    "    print(\"%-19s: %0.4f +/- %0.4f | \" % (s, z[k].mean(), z[k].std()/np.sqrt(m)), end='')\n",
    "    for i in range(m):\n",
    "        print(\"%0.4f \" % z[k,i], end='')\n",
    "    print()\n",
    "\n",
    "def main():\n",
    "    x = np.load(\"../data/breast/bc_features_standard.npy\")\n",
    "    y = np.load(\"../data/breast/bc_labels.npy\")\n",
    "    idx = np.argsort(np.random.random(y.shape[0]))\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    m = int(sys.argv[1])\n",
    "    z = np.zeros((8,m))\n",
    "\n",
    "    for k in range(m):\n",
    "        x_train, y_train, x_test, y_test = split(x,y,k,m)\n",
    "        z[0,k] = run(x_train, y_train, x_test, y_test, NearestCentroid())\n",
    "        z[1,k] = run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n",
    "        z[2,k] = run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))\n",
    "        z[3,k] = run(x_train, y_train, x_test, y_test, GaussianNB())\n",
    "        z[4,k] = run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n",
    "        z[5,k] = run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=5))\n",
    "        z[6,k] = run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=50))\n",
    "        z[7,k] = run(x_train, y_train, x_test, y_test, SVC(kernel=\"linear\", C=1.0))\n",
    "\n",
    "    pp(z,0,\"Nearest\"); pp(z,1,\"3-NN\")\n",
    "    pp(z,2,\"7-NN\");    pp(z,3,\"Naive Bayes\")\n",
    "    pp(z,4,\"Decision tree\");    pp(z,5,\"Random forest (5)\")\n",
    "    pp(z,6,\"Random forest (50)\");    pp(z,7,\"SVM (linear)\")\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC RBF SVM Search\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf.score(x_test, y_test)\n",
    "\n",
    "def split(x,y,k,m):\n",
    "    ns = int(y.shape[0]/m)\n",
    "    s = []\n",
    "    for i in range(m):\n",
    "        s.append([x[(ns*i):(ns*i+ns)], y[(ns*i):(ns*i+ns)]])\n",
    "    x_test, y_test = s[k]\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(m):\n",
    "        if (i==k):\n",
    "            continue\n",
    "        else:\n",
    "            a,b = s[i]\n",
    "            x_train.append(a)\n",
    "            y_train.append(b)\n",
    "    x_train = np.array(x_train).reshape(((m-1)*ns,30))\n",
    "    y_train = np.array(y_train).reshape((m-1)*ns)\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "def main():\n",
    "    m = 5 \n",
    "    x = np.load(\"../data/breast/bc_features_standard.npy\")\n",
    "    y = np.load(\"../data/breast/bc_labels.npy\")\n",
    "    idx = np.argsort(np.random.random(y.shape[0]))\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    Cs = np.array([0.01,0.1,1.0,2.0,10.0,50.0,100.0])\n",
    "    gs = (1./30)*2.0**np.array([-4,-3,-2,-1,0,1,2,3])\n",
    "    zmax = 0.0 \n",
    "    for C in Cs: \n",
    "        for g in gs: \n",
    "            z = np.zeros(m)\n",
    "            for k in range(m):\n",
    "                x_train, y_train, x_test, y_test = split(x,y,k,m)\n",
    "                z[k] = run(x_train, y_train, x_test, y_test, SVC(C=C,gamma=g,kernel=\"rbf\"))\n",
    "            if (z.mean() > zmax):\n",
    "                zmax = z.mean()\n",
    "                bestC = C \n",
    "                bestg = g \n",
    "    print(\"best C     = %0.5f\" % bestC)\n",
    "    print(\"     gamma = %0.5f\" % bestg)\n",
    "    print(\"   accuracy= %0.5f\" % zmax)\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed553cb4",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df99a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST experiments\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import decomposition\n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    s = time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    e_train = time.time() - s \n",
    "    s = time.time()\n",
    "    score = clf.score(x_test, y_test)\n",
    "    e_test = time.time() - s \n",
    "    print(\"score = %0.4f (time, train=%8.3f, test=%8.3f)\" % (score, e_train, e_test))\n",
    "\n",
    "def train(x_train, y_train, x_test, y_test):\n",
    "    print(\"    Nearest centroid          : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, NearestCentroid())\n",
    "    print(\"    k-NN classifier (k=3)     : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))\n",
    "    print(\"    k-NN classifier (k=7)     : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))\n",
    "    print(\"    Naive Bayes (Gaussian)    : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, GaussianNB())\n",
    "    print(\"    Decision tree             : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, DecisionTreeClassifier())\n",
    "    print(\"    Random forest (trees=  5) : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=5))\n",
    "    print(\"    Random forest (trees= 50) : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=50))\n",
    "    print(\"    Random forest (trees=500) : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=500))\n",
    "    print(\"    Random forest (trees=1000): \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, RandomForestClassifier(n_estimators=1000))\n",
    "    print(\"    LinearSVM (C=0.01)        : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, LinearSVC(C=0.01))\n",
    "    print(\"    LinearSVM (C=0.1)         : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, LinearSVC(C=0.1))\n",
    "    print(\"    LinearSVM (C=1.0)         : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, LinearSVC(C=1.0))\n",
    "    print(\"    LinearSVM (C=10.0)        : \", end='')\n",
    "    run(x_train, y_train, x_test, y_test, LinearSVC(C=10.0))\n",
    "\n",
    "def main():\n",
    "    x_train = np.load(\"../data/mnist/mnist_train_vectors.npy\").astype(\"float64\")\n",
    "    y_train = np.load(\"../data/mnist/mnist_train_labels.npy\")\n",
    "    x_test = np.load(\"../data/mnist/mnist_test_vectors.npy\").astype(\"float64\")\n",
    "    y_test = np.load(\"../data/mnist/mnist_test_labels.npy\")\n",
    "\n",
    "    print(\"Models trained on raw [0,255] images:\")\n",
    "    train(x_train, y_train, x_test, y_test)\n",
    "    print(\"Models trained on raw [0,1) images:\")\n",
    "    train(x_train/256.0, y_train, x_test/256.0, y_test)\n",
    "\n",
    "    m = x_train.mean(axis=0)\n",
    "    s = x_train.std(axis=0) + 1e-8\n",
    "    x_ntrain = (x_train - m) / s\n",
    "    x_ntest  = (x_test - m) / s\n",
    "\n",
    "    print(\"Models trained on normalized images:\")\n",
    "    train(x_ntrain, y_train, x_ntest, y_test)\n",
    "\n",
    "    pca = decomposition.PCA(n_components=15)\n",
    "    pca.fit(x_ntrain)\n",
    "    x_ptrain = pca.transform(x_ntrain)\n",
    "    x_ptest = pca.transform(x_ntest)\n",
    "    \n",
    "    print(\"Models trained on first 15 PCA components of normalized images:\")\n",
    "    train(x_ptrain, y_train, x_ptest, y_test)\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import decomposition\n",
    "\n",
    "def run(x_train, y_train, x_test, y_test, clf):\n",
    "    s = time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    e_train = time.time() - s \n",
    "    s = time.time()\n",
    "    score = clf.score(x_test, y_test)\n",
    "    e_test = time.time() - s \n",
    "    return [score, e_train, e_test]\n",
    "\n",
    "def main():\n",
    "    x_train = np.load(\"../data/mnist/mnist_train_vectors.npy\").astype(\"float64\")\n",
    "    y_train = np.load(\"../data/mnist/mnist_train_labels.npy\")\n",
    "    x_test = np.load(\"../data/mnist/mnist_test_vectors.npy\").astype(\"float64\")\n",
    "    y_test = np.load(\"../data/mnist/mnist_test_labels.npy\")\n",
    "    m = x_train.mean(axis=0)\n",
    "    s = x_train.std(axis=0) + 1e-8\n",
    "    x_ntrain = (x_train - m) / s \n",
    "    x_ntest  = (x_test - m) / s \n",
    "\n",
    "    n = 78\n",
    "    pcomp = np.linspace(10,780,n, dtype=\"int16\")\n",
    "    nb=np.zeros((n,4))\n",
    "    rf=np.zeros((n,4))\n",
    "    sv=np.zeros((n,4))\n",
    "    tv=np.zeros((n,2))\n",
    "\n",
    "    for i,p in enumerate(pcomp):\n",
    "        pca = decomposition.PCA(n_components=p)\n",
    "        pca.fit(x_ntrain)\n",
    "        xtrain = pca.transform(x_ntrain)\n",
    "        xtest = pca.transform(x_ntest)\n",
    "        tv[i,:] = [p, pca.explained_variance_ratio_.sum()]\n",
    "        sc,etrn,etst =run(xtrain, y_train, xtest, y_test, GaussianNB())\n",
    "        nb[i,:] = [p,sc,etrn,etst]\n",
    "        sc,etrn,etst =run(xtrain, y_train, xtest, y_test, RandomForestClassifier(n_estimators=50))\n",
    "        rf[i,:] = [p,sc,etrn,etst]\n",
    "        sc,etrn,etst =run(xtrain, y_train, xtest, y_test, LinearSVC(C=1.0))\n",
    "        sv[i,:] = [p,sc,etrn,etst]\n",
    "\n",
    "    np.save(\"../data/mnist/mnist_pca_tv.npy\", tv) \n",
    "    np.save(\"../data/mnist/mnist_pca_nb.npy\", nb)\n",
    "    np.save(\"../data/mnist/mnist_pca_rf.npy\", rf)\n",
    "    np.save(\"../data/mnist/mnist_pca_sv.npy\", sv)\n",
    "\n",
    "main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
