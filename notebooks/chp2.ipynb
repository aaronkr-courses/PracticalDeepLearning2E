{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f539279d",
   "metadata": {},
   "source": [
    "# Chp 2 Building the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9018d",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d9b2ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/iris/iris.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load Iris\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/iris/iris.data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     lines = [i[:-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m f.readlines()]\n\u001b[32m      7\u001b[39m n = [\u001b[33m\"\u001b[39m\u001b[33mIris-setosa\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mIris-versicolor\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mIris-virginica\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/iris/iris.data'"
     ]
    }
   ],
   "source": [
    "# Load Iris\n",
    "import numpy as np\n",
    "\n",
    "with open(\"../data/iris/iris.data\") as f:\n",
    "    lines = [i[:-1] for i in f.readlines()]\n",
    "\n",
    "n = [\"Iris-setosa\",\"Iris-versicolor\",\"Iris-virginica\"]\n",
    "x = [n.index(i.split(\",\")[-1]) for i in lines if i != \"\"] \n",
    "x = np.array(x, dtype=\"uint8\")\n",
    "\n",
    "y = [[float(j) for j in i.split(\",\")[:-1]] for i in lines if i != \"\"] \n",
    "y = np.array(y)\n",
    "\n",
    "i = np.argsort(np.random.random(x.shape[0]))\n",
    "x = x[i]\n",
    "y = y[i]\n",
    "\n",
    "np.save(\"../data/iris/iris_features.npy\", y)\n",
    "np.save(\"../data/iris/iris_labels.npy\", x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "253fdc2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Iris Augmentation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decomposition\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerateData\u001b[39m(pca, x, start):\n\u001b[32m      6\u001b[39m     original = pca.components_.copy()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Iris Augmentation\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "\n",
    "def generateData(pca, x, start):\n",
    "    original = pca.components_.copy()\n",
    "    ncomp = pca.components_.shape[0]\n",
    "    a = pca.transform(x)\n",
    "    for i in range(start, ncomp):\n",
    "        pca.components_[i,:] += np.random.normal(scale=0.1, size=ncomp)\n",
    "    b = pca.inverse_transform(a)\n",
    "    pca.components_ = original.copy()\n",
    "    return b\n",
    "\n",
    "def main():\n",
    "    x = np.load(\"../data/iris/iris_features.npy\")\n",
    "    y = np.load(\"../data/iris/iris_labels.npy\")\n",
    "\n",
    "    N = 120\n",
    "    x_train = x[:N]\n",
    "    y_train = y[:N]\n",
    "    x_test = x[N:]\n",
    "    y_test = y[N:]\n",
    "\n",
    "    pca = decomposition.PCA(n_components=4)\n",
    "    pca.fit(x)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    start = 2\n",
    "    \n",
    "    nsets = 10\n",
    "    nsamp = x_train.shape[0]\n",
    "    newx = np.zeros((nsets*nsamp, x_train.shape[1]))\n",
    "    newy = np.zeros(nsets*nsamp, dtype=\"uint8\")\n",
    "\n",
    "    for i in range(nsets):\n",
    "        if (i == 0):\n",
    "            newx[0:nsamp,:] = x_train\n",
    "            newy[0:nsamp] = y_train\n",
    "        else:\n",
    "            newx[(i*nsamp):(i*nsamp+nsamp),:] = generateData(pca, x_train, start)\n",
    "            newy[(i*nsamp):(i*nsamp+nsamp)] = y_train\n",
    "\n",
    "    idx = np.argsort(np.random.random(nsets*nsamp))\n",
    "    newx = newx[idx]\n",
    "    newy = newy[idx]\n",
    "\n",
    "    np.save(\"../data/iris/iris_train_features_augmented.npy\", newx)\n",
    "    np.save(\"../data/iris/iris_train_labels_augmented.npy\", newy)\n",
    "    np.save(\"../data/iris/iris_test_features_augmented.npy\", x_test)\n",
    "    np.save(\"../data/iris/iris_test_labels_augmented.npy\", y_test)\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0785b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris PCA Plots\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt \n",
    "from sklearn import decomposition\n",
    "\n",
    "x = np.load(\"../data/iris/iris_features.npy\")[:,:2]\n",
    "y = np.load(\"../data/iris/iris_labels.npy\")\n",
    "idx = np.where(y != 0)\n",
    "x = x[idx]\n",
    "x[:,0] -= x[:,0].mean()\n",
    "x[:,1] -= x[:,1].mean()\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(x)\n",
    "v = pca.explained_variance_ratio_\n",
    "   \n",
    "ax = plt.axes()\n",
    "plt.scatter(x[:,0],x[:,1],marker='o',color='b')\n",
    "x0 = v[0]*pca.components_[0,0]\n",
    "y0 = v[0]*pca.components_[0,1]\n",
    "ax.arrow(0, 0, x0, y0, head_width=0.05, head_length=0.1, fc='r', ec='r')\n",
    "x1 = v[1]*pca.components_[1,0]\n",
    "y1 = v[1]*pca.components_[1,1]\n",
    "ax.arrow(0, 0, x1, y1, head_width=0.05, head_length=0.1, fc='r', ec='r')\n",
    "plt.xlabel(\"$x_0$\", fontsize=16)\n",
    "plt.ylabel(\"$x_1$\", fontsize=16)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a38a4",
   "metadata": {},
   "source": [
    "## Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ae9463",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m../data/breast/wdbc.data\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     lines = [i[:-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m f.readlines() \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m] \n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"../data/breast/wdbc.data\") as f:\n",
    "    lines = [i[:-1] for i in f.readlines() if i != \"\"] \n",
    "\n",
    "n = [\"B\",\"M\"]\n",
    "x = np.array([n.index(i.split(\",\")[1]) for i in lines],dtype=\"uint8\")\n",
    "y = np.array([[float(j) for j in i.split(\",\")[2:]] for i in lines])\n",
    "i = np.argsort(np.random.random(x.shape[0]))\n",
    "x = x[i]\n",
    "y = y[i]\n",
    "z = (y - y.mean(axis=0)) / y.std(axis=0)\n",
    "\n",
    "np.save(\"../data/breast/bc_features.npy\", y)\n",
    "np.save(\"../data/breast/bc_features_standard.npy\", z)\n",
    "np.save(\"../data/breast/bc_labels.npy\", x)\n",
    "plt.boxplot(z)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c18bbe2",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(xtrn, ytrn), (xtst, ytst) = cifar10.load_data()\n",
    "idx = np.argsort(np.random.random(ytrn.shape[0]))\n",
    "xtrn = xtrn[idx]\n",
    "ytrn = ytrn[idx]\n",
    "idx = np.argsort(np.random.random(ytst.shape[0]))\n",
    "xtst = xtst[idx]\n",
    "ytst = ytst[idx]\n",
    "\n",
    "os.system(\"mkdir ../data/cifar10/\")\n",
    "np.save(\"../data/cifar10/cifar10_train_images.npy\", xtrn)\n",
    "np.save(\"../data/cifar10/cifar10_train_labels.npy\", ytrn)\n",
    "np.save(\"../data/cifar10/cifar10_test_images.npy\", xtst)\n",
    "np.save(\"../data/cifar10/cifar10_test_labels.npy\", ytst)\n",
    "\n",
    "xtrnv = xtrn.reshape((50000,32*32*3))\n",
    "xtstv = xtst.reshape((10000,32*32*3))\n",
    "np.save(\"../data/cifar10/cifar10_train_vectors.npy\", xtrnv)\n",
    "np.save(\"../data/cifar10/cifar10_test_vectors.npy\", xtstv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c194872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment CIFAR-10\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def augment(im, dim):\n",
    "    img = Image.fromarray(im)\n",
    "    if (np.random.random() < 0.5):\n",
    "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    if (np.random.random() < 0.3333):\n",
    "        z = (32-dim)/2\n",
    "        r = 10*np.random.random()-5\n",
    "        img = img.rotate(r, resample=Image.BILINEAR)\n",
    "        img = img.crop((z,z,32-z,32-z))\n",
    "    else:\n",
    "        x = int((32-dim-1)*np.random.random())\n",
    "        y = int((32-dim-1)*np.random.random())\n",
    "        img = img.crop((x,y,x+dim,y+dim))\n",
    "    return np.array(img)\n",
    "\n",
    "def main():\n",
    "    x = np.load(\"../data/cifar10/cifar10_train_images.npy\")\n",
    "    y = np.load(\"../data/cifar10/cifar10_train_labels.npy\")\n",
    "    factor = 10\n",
    "    dim = 28\n",
    "    z = (32-dim)/2\n",
    "    newx = np.zeros((x.shape[0]*factor, dim,dim,3), dtype=\"uint8\")\n",
    "    newy = np.zeros(y.shape[0]*factor, dtype=\"uint8\")\n",
    "    k=0 \n",
    "    for i in range(x.shape[0]):\n",
    "        im = Image.fromarray(x[i,:])\n",
    "        im = im.crop((z,z,32-z,32-z))\n",
    "        newx[k,...] = np.array(im)\n",
    "        newy[k] = y[i,0]\n",
    "        k += 1\n",
    "        for j in range(factor-1):\n",
    "            newx[k,...] = augment(x[i,:], dim)\n",
    "            newy[k] = y[i,0]\n",
    "            k += 1\n",
    "    idx = np.argsort(np.random.random(newx.shape[0]))\n",
    "    newx = newx[idx]\n",
    "    newy = newy[idx]\n",
    "    np.save(\"../data/cifar10/cifar10_aug_train_images.npy\", newx)\n",
    "    np.save(\"../data/cifar10/cifar10_aug_train_labels.npy\", newy)\n",
    "\n",
    "    x = np.load(\"../data/cifar10/cifar10_test_images.npy\")\n",
    "    newx = np.zeros((x.shape[0], dim,dim,3), dtype=\"uint8\")\n",
    "    for i in range(x.shape[0]):\n",
    "        im = Image.fromarray(x[i,:])\n",
    "        im = im.crop((z,z,32-z,32-z))\n",
    "        newx[i,...] = np.array(im)\n",
    "    np.save(\"../data/cifar10/cifar10_aug_test_images.npy\", newx)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9f7c2",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4999abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac URL SSL fix\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt \n",
    "from sklearn import decomposition\n",
    "\n",
    "x = np.load(\"../data/iris/iris_features.npy\")[:,:2]\n",
    "y = np.load(\"../data/iris/iris_labels.npy\")\n",
    "idx = np.where(y != 0)\n",
    "x = x[idx]\n",
    "x[:,0] -= x[:,0].mean()\n",
    "x[:,1] -= x[:,1].mean()\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(x)\n",
    "v = pca.explained_variance_ratio_\n",
    "   \n",
    "ax = plt.axes()\n",
    "plt.scatter(x[:,0],x[:,1],marker='o',color='b')\n",
    "x0 = v[0]*pca.components_[0,0]\n",
    "y0 = v[0]*pca.components_[0,1]\n",
    "ax.arrow(0, 0, x0, y0, head_width=0.05, head_length=0.1, fc='r', ec='r')\n",
    "x1 = v[1]*pca.components_[1,0]\n",
    "y1 = v[1]*pca.components_[1,1]\n",
    "ax.arrow(0, 0, x1, y1, head_width=0.05, head_length=0.1, fc='r', ec='r')\n",
    "plt.xlabel(\"$x_0$\", fontsize=16)\n",
    "plt.ylabel(\"$x_1$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f89aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6608118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MNIST\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(xtrn, ytrn), (xtst, ytst) = mnist.load_data()\n",
    "idx = np.argsort(np.random.random(ytrn.shape[0]))\n",
    "xtrn = xtrn[idx]\n",
    "ytrn = ytrn[idx]\n",
    "idx = np.argsort(np.random.random(ytst.shape[0]))\n",
    "xtst = xtst[idx]\n",
    "ytst = ytst[idx]\n",
    "\n",
    "np.save(\"../data/mnist/mnist_train_images.npy\", xtrn)\n",
    "np.save(\"../data/mnist/mnist_train_labels.npy\", ytrn)\n",
    "np.save(\"../data/mnist/mnist_test_images.npy\", xtst)\n",
    "np.save(\"../data/mnist/mnist_test_labels.npy\", ytst)\n",
    "\n",
    "xtrnv = xtrn.reshape((60000,28*28))\n",
    "xtstv = xtst.reshape((10000,28*28))\n",
    "np.save(\"../data/mnist/mnist_train_vectors.npy\", xtrnv)\n",
    "np.save(\"../data/mnist/mnist_test_vectors.npy\", xtstv)\n",
    "\n",
    "idx = np.argsort(np.random.random(28*28))\n",
    "for i in range(60000):\n",
    "    xtrnv[i,:] = xtrnv[i,idx]\n",
    "for i in range(10000):\n",
    "    xtstv[i,:] = xtstv[i,idx]\n",
    "np.save(\"../data/mnist/mnist_train_scrambled_vectors.npy\", xtrnv)\n",
    "np.save(\"../data/mnist/mnist_test_scrambled_vectors.npy\", xtstv)\n",
    "\n",
    "t = np.zeros((60000,28,28))\n",
    "for i in range(60000):\n",
    "    t[i,:,:] = xtrnv[i,:].reshape((28,28))\n",
    "np.save(\"../data/mnist/mnist_train_scrambled_images.npy\", t)\n",
    "t = np.zeros((10000,28,28))\n",
    "for i in range(10000):\n",
    "    t[i,:,:] = xtstv[i,:].reshape((28,28))\n",
    "np.save(\"../data/mnist/mnist_test_scrambled_images.npy\", t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c4549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
