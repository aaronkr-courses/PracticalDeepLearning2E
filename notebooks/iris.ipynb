{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb9d9d7",
   "metadata": {},
   "source": [
    "# Clustering Analysis with K-Means and K-Folds Cross-Validation\n",
    "\n",
    "## Dataset: Iris\n",
    "\n",
    "### Duration: ~60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ecbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and Explore the Iris Dataset\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create a DataFrame for easier exploration\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "\n",
    "print(\"Dataset Shape:\", X.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(df.describe())\n",
    "print(\"\\nSpecies Distribution:\")\n",
    "print(df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8384e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Visualize the Dataset - Pairplot\n",
    "# Create a pairplot to see relationships between features\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.pairplot(df, hue='species', palette='viridis', markers=['o', 's', 'D'])\n",
    "plt.suptitle('Iris Dataset: Feature Relationships', y=1.02, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a21bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data Preprocessing and Splitting\n",
    "# Standardize the features (important for K-Means)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data: 60% train, 20% validation, 20% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_scaled, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Data Split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: K-Means Clustering - Finding Optimal K (Elbow Method)\n",
    "# Test different numbers of clusters\n",
    "k_values = range(2, 11)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_train)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_train, kmeans.labels_))\n",
    "\n",
    "# Plot Elbow Curve and Silhouette Scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Elbow Method\n",
    "axes[0].plot(k_values, inertias, 'bo-', linewidth=2, markersize=10)\n",
    "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Inertia (Within-Cluster Sum of Squares)', fontsize=12)\n",
    "axes[0].set_title('Elbow Method for Optimal K', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Silhouette Score\n",
    "axes[1].plot(k_values, silhouette_scores, 'ro-', linewidth=2, markersize=10)\n",
    "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].set_title('Silhouette Score vs Number of Clusters', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Higher silhouette score indicates better-defined clusters (closer to 1 is better)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdcd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Visualizing Decision Boundaries for Different K Values (2D)\n",
    "# We'll use the first two features for 2D visualization\n",
    "def plot_decision_boundaries_2d(X, k_list, feature_indices=(0, 1)):\n",
    "    \"\"\"Plot decision boundaries for different k values in 2D\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(k_list), figsize=(18, 5))\n",
    "    \n",
    "    # Get the features we're using\n",
    "    X_2d = X[:, feature_indices]\n",
    "    \n",
    "    # Create mesh for decision boundaries\n",
    "    h = 0.02  # step size in the mesh\n",
    "    x_min, x_max = X_2d[:, 0].min() - 0.5, X_2d[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_2d[:, 1].min() - 0.5, X_2d[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    for idx, k in enumerate(k_list):\n",
    "        # Fit K-Means\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X_2d)\n",
    "        \n",
    "        # Predict on mesh\n",
    "        Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        \n",
    "        # Plot\n",
    "        ax = axes[idx]\n",
    "        ax.contourf(xx, yy, Z, alpha=0.4, cmap='viridis', levels=k-1)\n",
    "        ax.scatter(X_2d[:, 0], X_2d[:, 1], c=kmeans.labels_, \n",
    "                  s=50, cmap='viridis', edgecolors='black', linewidth=0.5)\n",
    "        ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "                  marker='X', s=300, c='red', edgecolors='black', linewidth=2,\n",
    "                  label='Centroids')\n",
    "        \n",
    "        ax.set_title(f'K = {k} Clusters', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(iris.feature_names[feature_indices[0]], fontsize=10)\n",
    "        ax.set_ylabel(iris.feature_names[feature_indices[1]], fontsize=10)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('K-Means Decision Boundaries with Different K Values (2D)', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize with k=3, 5, 7\n",
    "plot_decision_boundaries_2d(X_train, k_list=[3, 5, 7], feature_indices=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd327c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: More 2D Visualizations with Different Feature Pairs\n",
    "# Let's try different feature combinations\n",
    "feature_pairs = [(0, 1), (2, 3), (0, 2)]\n",
    "feature_names_pairs = [\n",
    "    (iris.feature_names[0], iris.feature_names[1]),\n",
    "    (iris.feature_names[2], iris.feature_names[3]),\n",
    "    (iris.feature_names[0], iris.feature_names[2])\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "k = 3  # Using 3 clusters (same as actual species)\n",
    "for idx, (feat_pair, feat_names) in enumerate(zip(feature_pairs, feature_names_pairs)):\n",
    "    X_2d = X_train[:, feat_pair]\n",
    "    \n",
    "    # Create mesh\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_2d[:, 0].min() - 0.5, X_2d[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_2d[:, 1].min() - 0.5, X_2d[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Fit and predict\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_2d)\n",
    "    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
    "    ax.scatter(X_2d[:, 0], X_2d[:, 1], c=kmeans.labels_, \n",
    "              s=60, cmap='viridis', edgecolors='black', linewidth=0.5)\n",
    "    ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "              marker='X', s=300, c='red', edgecolors='black', linewidth=2)\n",
    "    \n",
    "    ax.set_title(f'{feat_names[0]} vs {feat_names[1]}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(feat_names[0], fontsize=10)\n",
    "    ax.set_ylabel(feat_names[1], fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('K-Means Clustering (k=3) on Different Feature Pairs', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: 3D Visualization of Clustering\n",
    "# Using first 3 features for 3D visualization\n",
    "def plot_3d_clusters(X, k_list):\n",
    "    \"\"\"Plot 3D clusters for different k values\"\"\"\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    \n",
    "    X_3d = X[:, :3]  # First 3 features\n",
    "    \n",
    "    for idx, k in enumerate(k_list):\n",
    "        ax = fig.add_subplot(1, len(k_list), idx+1, projection='3d')\n",
    "        \n",
    "        # Fit K-Means\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X_3d)\n",
    "        \n",
    "        # Plot data points\n",
    "        scatter = ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2],\n",
    "                           c=kmeans.labels_, s=50, cmap='viridis',\n",
    "                           edgecolors='black', linewidth=0.5, alpha=0.7)\n",
    "        \n",
    "        # Plot centroids\n",
    "        ax.scatter(kmeans.cluster_centers_[:, 0],\n",
    "                  kmeans.cluster_centers_[:, 1],\n",
    "                  kmeans.cluster_centers_[:, 2],\n",
    "                  marker='X', s=300, c='red', edgecolors='black', linewidth=2,\n",
    "                  label='Centroids')\n",
    "        \n",
    "        ax.set_xlabel(iris.feature_names[0], fontsize=10)\n",
    "        ax.set_ylabel(iris.feature_names[1], fontsize=10)\n",
    "        ax.set_zlabel(iris.feature_names[2], fontsize=10)\n",
    "        ax.set_title(f'K = {k} Clusters (3D)', fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.colorbar(scatter, ax=ax, pad=0.1, shrink=0.8)\n",
    "    \n",
    "    plt.suptitle('3D K-Means Clustering with Different K Values', \n",
    "                 fontsize=16, fontweight='bold', y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_3d_clusters(X_train, k_list=[3, 5, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14efcf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Compare 2D vs 3D Clustering (Same Data)\n",
    "# Direct comparison for k=3\n",
    "fig = plt.figure(figsize=(18, 7))\n",
    "\n",
    "k = 3\n",
    "kmeans_2d = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "kmeans_3d = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "\n",
    "# 2D clustering (using first 2 features)\n",
    "X_2d = X_train[:, :2]\n",
    "kmeans_2d.fit(X_2d)\n",
    "\n",
    "# Create mesh for 2D\n",
    "h = 0.02\n",
    "x_min, x_max = X_2d[:, 0].min() - 0.5, X_2d[:, 0].max() + 0.5\n",
    "y_min, y_max = X_2d[:, 1].min() - 0.5, X_2d[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = kmeans_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot 2D\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
    "ax1.scatter(X_2d[:, 0], X_2d[:, 1], c=kmeans_2d.labels_, \n",
    "           s=60, cmap='viridis', edgecolors='black', linewidth=0.5)\n",
    "ax1.scatter(kmeans_2d.cluster_centers_[:, 0], kmeans_2d.cluster_centers_[:, 1],\n",
    "           marker='X', s=300, c='red', edgecolors='black', linewidth=2)\n",
    "ax1.set_xlabel(iris.feature_names[0], fontsize=12)\n",
    "ax1.set_ylabel(iris.feature_names[1], fontsize=12)\n",
    "ax1.set_title('2D Clustering (2 features)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 3D clustering (using first 3 features)\n",
    "X_3d = X_train[:, :3]\n",
    "kmeans_3d.fit(X_3d)\n",
    "\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "scatter = ax2.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2],\n",
    "                     c=kmeans_3d.labels_, s=60, cmap='viridis',\n",
    "                     edgecolors='black', linewidth=0.5, alpha=0.7)\n",
    "ax2.scatter(kmeans_3d.cluster_centers_[:, 0],\n",
    "           kmeans_3d.cluster_centers_[:, 1],\n",
    "           kmeans_3d.cluster_centers_[:, 2],\n",
    "           marker='X', s=300, c='red', edgecolors='black', linewidth=2)\n",
    "ax2.set_xlabel(iris.feature_names[0], fontsize=12)\n",
    "ax2.set_ylabel(iris.feature_names[1], fontsize=12)\n",
    "ax2.set_zlabel(iris.feature_names[2], fontsize=12)\n",
    "ax2.set_title('3D Clustering (3 features)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Comparison: 2D vs 3D K-Means Clustering (k=3)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare clustering quality\n",
    "sil_2d = silhouette_score(X_2d, kmeans_2d.labels_)\n",
    "sil_3d = silhouette_score(X_3d, kmeans_3d.labels_)\n",
    "\n",
    "print(f\"\\nClustering Quality Comparison:\")\n",
    "print(f\"2D Silhouette Score: {sil_2d:.3f}\")\n",
    "print(f\"3D Silhouette Score: {sil_3d:.3f}\")\n",
    "print(f\"\\nThe {'3D' if sil_3d > sil_2d else '2D'} clustering is better defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309972d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: K-Folds Cross-Validation\n",
    "# Using k=3 clusters and 5-fold cross-validation\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def kmeans_score(X, y):\n",
    "    \"\"\"Custom scoring function for K-Means\"\"\"\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    return silhouette_score(X, kmeans.labels_)\n",
    "\n",
    "# Perform K-Folds cross-validation\n",
    "kfolds = 5\n",
    "kf = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "fold_number = 1\n",
    "\n",
    "print(f\"Performing {kfolds}-Fold Cross-Validation for K-Means (k=3):\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "    \n",
    "    # Train K-Means on fold\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_fold_train)\n",
    "    \n",
    "    # Evaluate on validation fold\n",
    "    val_labels = kmeans.predict(X_fold_val)\n",
    "    score = silhouette_score(X_fold_val, val_labels)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold_number}: Silhouette Score = {score:.4f}\")\n",
    "    fold_number += 1\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nMean Silhouette Score: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "print(f\"Best Fold: {np.argmax(fold_scores) + 1} (Score: {np.max(fold_scores):.4f})\")\n",
    "print(f\"Worst Fold: {np.argmin(fold_scores) + 1} (Score: {np.min(fold_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Visualize K-Folds Results\n",
    "# Plot the scores from each fold\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar plot of fold scores\n",
    "axes[0].bar(range(1, kfolds+1), fold_scores, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axhline(np.mean(fold_scores), color='red', linestyle='--', linewidth=2, label='Mean Score')\n",
    "axes[0].set_xlabel('Fold Number', fontsize=12)\n",
    "axes[0].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[0].set_title('K-Folds Cross-Validation Results', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(range(1, kfolds+1))\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(fold_scores, vert=True, patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                medianprops=dict(color='red', linewidth=2))\n",
    "axes[1].scatter([1]*len(fold_scores), fold_scores, color='blue', s=100, \n",
    "               alpha=0.6, edgecolors='black', zorder=3)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].set_title('Score Distribution Across Folds', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticklabels(['K=3 Clusters'])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Final Model Evaluation on Test Set\n",
    "# Train final model on training data\n",
    "final_kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "final_kmeans.fit(X_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_predictions = final_kmeans.predict(X_val)\n",
    "val_silhouette = silhouette_score(X_val, val_predictions)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_predictions = final_kmeans.predict(X_test)\n",
    "test_silhouette = silhouette_score(X_test, test_predictions)\n",
    "\n",
    "print(\"Final Model Performance:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training Silhouette Score:   {silhouette_score(X_train, final_kmeans.labels_):.4f}\")\n",
    "print(f\"Validation Silhouette Score: {val_silhouette:.4f}\")\n",
    "print(f\"Test Silhouette Score:       {test_silhouette:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Visualize Final Model Performance (Train, Val, Test)\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "datasets = [\n",
    "    (X_train, final_kmeans.labels_, 'Training Set'),\n",
    "    (X_val, val_predictions, 'Validation Set'),\n",
    "    (X_test, test_predictions, 'Test Set')\n",
    "]\n",
    "\n",
    "for idx, (X_data, labels, title) in enumerate(datasets):\n",
    "    ax = fig.add_subplot(1, 3, idx+1, projection='3d')\n",
    "    \n",
    "    X_3d = X_data[:, :3]\n",
    "    scatter = ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2],\n",
    "                        c=labels, s=60, cmap='viridis',\n",
    "                        edgecolors='black', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "    if idx == 0:  # Only show centroids for training set\n",
    "        ax.scatter(final_kmeans.cluster_centers_[:, 0],\n",
    "                  final_kmeans.cluster_centers_[:, 1],\n",
    "                  final_kmeans.cluster_centers_[:, 2],\n",
    "                  marker='X', s=300, c='red', edgecolors='black', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel(iris.feature_names[0], fontsize=10)\n",
    "    ax.set_ylabel(iris.feature_names[1], fontsize=10)\n",
    "    ax.set_zlabel(iris.feature_names[2], fontsize=10)\n",
    "    ax.set_title(f'{title}', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(scatter, ax=ax, pad=0.1, shrink=0.8)\n",
    "\n",
    "plt.suptitle('Final K-Means Model: Train, Validation, and Test Sets', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Summary and Metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLUSTERING ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Information:\")\n",
    "print(f\"   â€¢ Total samples: {len(X)}\")\n",
    "print(f\"   â€¢ Features: {X.shape[1]} ({', '.join(iris.feature_names)})\")\n",
    "print(f\"   â€¢ True classes: {len(iris.target_names)} ({', '.join(iris.target_names)})\")\n",
    "\n",
    "print(f\"\\nðŸ”„ Data Split:\")\n",
    "print(f\"   â€¢ Training: {len(X_train)} samples (60%)\")\n",
    "print(f\"   â€¢ Validation: {len(X_val)} samples (20%)\")\n",
    "print(f\"   â€¢ Test: {len(X_test)} samples (20%)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Optimal Clusters: k = 3\")\n",
    "print(f\"   â€¢ Based on elbow method and silhouette score\")\n",
    "print(f\"   â€¢ Matches the number of true species!\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Model Performance:\")\n",
    "print(f\"   â€¢ Training Silhouette: {silhouette_score(X_train, final_kmeans.labels_):.4f}\")\n",
    "print(f\"   â€¢ Validation Silhouette: {val_silhouette:.4f}\")\n",
    "print(f\"   â€¢ Test Silhouette: {test_silhouette:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ”€ Cross-Validation ({kfolds}-Folds):\")\n",
    "print(f\"   â€¢ Mean Score: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "print(f\"   â€¢ Score Range: [{np.min(fold_scores):.4f}, {np.max(fold_scores):.4f}]\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Key Insights:\")\n",
    "print(f\"   â€¢ 3D clustering provides better separation than 2D\")\n",
    "print(f\"   â€¢ Decision boundaries clearly separate different clusters\")\n",
    "print(f\"   â€¢ Model shows consistent performance across all data splits\")\n",
    "print(f\"   â€¢ K-folds validation confirms model stability\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Analysis Complete!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
